#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excelæ–‡ä»¶Cåˆ—é‡å¤å€¼åˆ†æå·¥å…·
åˆ†ææŒ‡å®šExcelæ–‡ä»¶ä¸­Cåˆ—çš„å€¼æ˜¯å¦å­˜åœ¨é‡å¤ï¼Œå¹¶åˆ—å‡ºé‡å¤å€¼åŠå…¶æ‰€åœ¨çš„è¡Œæ•°
"""

import pandas as pd
import sys
import os
from collections import defaultdict
import argparse


def analyze_excel_duplicates(file_path, sheet_name=None, column_name='C'):
    """
    åˆ†æExcelæ–‡ä»¶ä¸­æŒ‡å®šåˆ—çš„é‡å¤å€¼
    
    Args:
        file_path (str): Excelæ–‡ä»¶è·¯å¾„
        sheet_name (str, optional): å·¥ä½œè¡¨åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        column_name (str): è¦åˆ†æçš„åˆ—åï¼Œé»˜è®¤ä¸º'C'
    
    Returns:
        dict: åŒ…å«é‡å¤å€¼åˆ†æç»“æœçš„å­—å…¸
    """
    try:
        # è¯»å–Excelæ–‡ä»¶
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
        else:
            df = pd.read_excel(file_path)
        
        print(f"ğŸ“Š æ–‡ä»¶ä¿¡æ¯:")
        print(f"   æ–‡ä»¶è·¯å¾„: {file_path}")
        print(f"   å·¥ä½œè¡¨: {sheet_name if sheet_name else 'ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨'}")
        print(f"   æ€»è¡Œæ•°: {len(df)}")
        print(f"   æ€»åˆ—æ•°: {len(df.columns)}")
        print()
        
        # è·å–åˆ—å
        if column_name.isalpha():
            # å¦‚æœcolumn_nameæ˜¯å­—æ¯ï¼Œè½¬æ¢ä¸ºåˆ—ç´¢å¼•
            col_index = ord(column_name.upper()) - ord('A')
            if col_index >= len(df.columns):
                print(f"âŒ é”™è¯¯: åˆ— '{column_name}' ä¸å­˜åœ¨ï¼Œæ–‡ä»¶åªæœ‰ {len(df.columns)} åˆ—")
                return None
            actual_column = df.columns[col_index]
        else:
            # å¦‚æœcolumn_nameæ˜¯åˆ—å
            if column_name not in df.columns:
                print(f"âŒ é”™è¯¯: åˆ— '{column_name}' ä¸å­˜åœ¨")
                print(f"   å¯ç”¨çš„åˆ—: {list(df.columns)}")
                return None
            actual_column = column_name
        
        print(f"ğŸ” åˆ†æåˆ—: {actual_column} (ç¬¬{column_name}åˆ—)")
        print()
        
        # è·å–Cåˆ—çš„æ•°æ®
        column_data = df[actual_column]
        
        # ç»Ÿè®¡æ¯ä¸ªå€¼çš„å‡ºç°æ¬¡æ•°å’Œè¡Œå·
        value_positions = defaultdict(list)
        for index, value in enumerate(column_data, start=1):  # ä»1å¼€å§‹è®¡æ•°ï¼ˆExcelè¡Œå·ï¼‰
            # å¤„ç†NaNå€¼
            if pd.isna(value):
                value_positions['<ç©ºå€¼>'].append(index)
            else:
                value_positions[str(value)].append(index)
        
        # æ‰¾å‡ºé‡å¤å€¼
        duplicates = {value: positions for value, positions in value_positions.items() 
                     if len(positions) > 1}
        
        # è¾“å‡ºç»“æœ
        print("=" * 60)
        print("ğŸ“‹ åˆ†æç»“æœ")
        print("=" * 60)
        
        if not duplicates:
            print("âœ… æœªå‘ç°é‡å¤å€¼ï¼Cåˆ—ä¸­çš„æ‰€æœ‰å€¼éƒ½æ˜¯å”¯ä¸€çš„ã€‚")
        else:
            print(f"âš ï¸  å‘ç° {len(duplicates)} ä¸ªé‡å¤å€¼:")
            print()
            
            for i, (value, positions) in enumerate(duplicates.items(), 1):
                print(f"{i}. é‡å¤å€¼: '{value}'")
                print(f"   å‡ºç°æ¬¡æ•°: {len(positions)}")
                print(f"   æ‰€åœ¨è¡Œå·: {', '.join(map(str, positions))}")
                print(f"   è¡Œå·èŒƒå›´: {min(positions)} - {max(positions)}")
                print()
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_values = len(column_data)
        unique_values = len(value_positions)
        duplicate_values = len(duplicates)
        
        print("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è¡Œæ•°: {total_values}")
        print(f"   å”¯ä¸€å€¼æ•°é‡: {unique_values}")
        print(f"   é‡å¤å€¼æ•°é‡: {duplicate_values}")
        print(f"   é‡å¤ç‡: {duplicate_values/unique_values*100:.2f}%")
        
        return {
            'total_rows': total_values,
            'unique_values': unique_values,
            'duplicate_values': duplicate_values,
            'duplicates': duplicates
        }
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨")
        return None
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åˆ†æExcelæ–‡ä»¶ä¸­Cåˆ—çš„é‡å¤å€¼')
    parser.add_argument('file_path', help='Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-s', '--sheet', help='å·¥ä½œè¡¨åç§°ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('-c', '--column', default='C', help='è¦åˆ†æçš„åˆ—åæˆ–åˆ—å­—æ¯ï¼ˆé»˜è®¤ï¼šCï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.file_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{args.file_path}' ä¸å­˜åœ¨")
        return
    
    # åˆ†æé‡å¤å€¼
    result = analyze_excel_duplicates(args.file_path, args.sheet, args.column)
    
    if result and result['duplicates']:
        print("\n" + "=" * 60)
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥é‡å¤å€¼æ˜¯å¦ä¸ºé¢„æœŸç»“æœ")
        print("   2. å¦‚æœæ˜¯æ•°æ®é”™è¯¯ï¼Œè¯·ä¿®æ­£ç›¸åº”çš„è¡Œ")
        print("   3. å¦‚æœæ˜¯é¢„æœŸç»“æœï¼Œå¯ä»¥è€ƒè™‘å»é‡å¤„ç†")


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæä¾›äº¤äº’å¼è¾“å…¥
    if len(sys.argv) == 1:
        print("ğŸ” Excelæ–‡ä»¶Cåˆ—é‡å¤å€¼åˆ†æå·¥å…·")
        print("=" * 40)
        
        file_path = input("è¯·è¾“å…¥Excelæ–‡ä»¶è·¯å¾„: ").strip()
        if not file_path:
            print("âŒ æœªè¾“å…¥æ–‡ä»¶è·¯å¾„")
            sys.exit(1)
        
        sheet_name = input("è¯·è¾“å…¥å·¥ä½œè¡¨åç§°ï¼ˆå¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡ï¼‰: ").strip()
        if not sheet_name:
            sheet_name = None
        
        column = input("è¯·è¾“å…¥è¦åˆ†æçš„åˆ—ï¼ˆé»˜è®¤Cåˆ—ï¼Œç›´æ¥å›è½¦ä½¿ç”¨Cï¼‰: ").strip()
        if not column:
            column = 'C'
        
        result = analyze_excel_duplicates(file_path, sheet_name, column)
        
        if result and result['duplicates']:
            print("\n" + "=" * 60)
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥é‡å¤å€¼æ˜¯å¦ä¸ºé¢„æœŸç»“æœ")
            print("   2. å¦‚æœæ˜¯æ•°æ®é”™è¯¯ï¼Œè¯·ä¿®æ­£ç›¸åº”çš„è¡Œ")
            print("   3. å¦‚æœæ˜¯é¢„æœŸç»“æœï¼Œå¯ä»¥è€ƒè™‘å»é‡å¤„ç†")
    else:
        main()


